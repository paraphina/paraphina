# =============================================================================
# sim-eval-research.yml
#
# Quant-grade CI workflow for research experiments with ablation studies.
#
# Security:
#   - Uses only GITHUB_TOKEN with minimal read permissions
#   - No PATs, SSH keys, or secrets exposed
#
# Reproducibility:
#   - Unique RUN_ROOT per run (includes github.run_id)
#   - All bash scripts use set -euo pipefail
#   - All paths are quoted
#   - Deterministic glob ordering via sorted arrays
#
# Concurrency:
#   - cancel-in-progress: false - allows parallel runs for different refs
#   - Prevents stomping between workflow_dispatch runs on same ref
#
# =============================================================================

name: sim-eval-research

on:
  workflow_dispatch:
    inputs:
      suite_path:
        description: "Suite YAML path in repo"
        required: true
        default: "scenarios/suites/research_v1.yaml"
      repeat_runs:
        description: "Repeat runs per seed (empty = use suite default). NOTE: Currently informational only; sim_eval uses suite's repeat_runs value."
        required: false
        default: ""
      ablations:
        description: "Comma-separated ablation IDs (empty = baseline only)"
        required: false
        default: ""
      run_all_default_ablations:
        description: "Run matrix across standard ablations (disable_vol_floor, disable_toxicity_gate, disable_risk_regime)"
        required: false
        type: boolean
        default: false

# Minimal permissions - only need to read repo contents
permissions:
  contents: read

# Prevent overlapping workflow_dispatch runs from conflicting
# cancel-in-progress: false ensures existing runs complete (important for research)
concurrency:
  group: sim-eval-research-${{ github.ref }}
  cancel-in-progress: false

jobs:
  research:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    # Environment variables for consistent path contracts
    env:
      # Unique output root per run to prevent stomping
      RUN_ROOT: "runs/ci/${{ github.run_id }}"
      REPORT_DIR: "_reports"
      # Standard ablation IDs for run_all_default_ablations
      DEFAULT_ABLATIONS: "disable_vol_floor,disable_toxicity_gate,disable_risk_regime"

    steps:
      # =========================================================================
      # Setup
      # =========================================================================

      - name: Checkout
        uses: actions/checkout@v4

      - name: Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Rust cache
        uses: Swatinem/rust-cache@v2

      - name: Build sim_eval (release)
        shell: bash
        run: |
          set -euo pipefail
          cargo build --locked --release -p paraphina --bin sim_eval
          echo "‚úì sim_eval built successfully"

      # =========================================================================
      # Compute effective configuration
      # =========================================================================

      - name: Compute run configuration
        id: config
        shell: bash
        env:
          INPUT_SUITE_PATH: ${{ inputs.suite_path }}
          INPUT_ABLATIONS: ${{ inputs.ablations }}
          INPUT_RUN_ALL_DEFAULT: ${{ inputs.run_all_default_ablations }}
        run: |
          set -euo pipefail

          SUITE_PATH="${INPUT_SUITE_PATH}"
          RUN_ROOT="${{ env.RUN_ROOT }}"
          REPORT_DIR="${{ env.REPORT_DIR }}"
          DEFAULT_ABLATIONS="${{ env.DEFAULT_ABLATIONS }}"

          echo "=== Input Configuration ==="
          echo "suite_path: ${SUITE_PATH}"
          echo "ablations input: '${INPUT_ABLATIONS}'"
          echo "run_all_default_ablations: ${INPUT_RUN_ALL_DEFAULT}"
          echo "run_root: ${RUN_ROOT}"
          echo "report_dir: ${REPORT_DIR}"
          echo ""

          # Parse out_dir from suite YAML for naming reference
          SUITE_OUT_DIR="$(python3 -c "
          import sys
          path = sys.argv[1]
          for raw in open(path, 'r', encoding='utf-8'):
              line = raw.split('#', 1)[0].strip()
              if line.startswith('out_dir:'):
                  print(line.split(':', 1)[1].strip())
                  sys.exit(0)
          print('runs/research')  # default fallback
          " "${SUITE_PATH}")"
          echo "suite_out_dir: ${SUITE_OUT_DIR}"

          # Compute ablation list
          # Note: GitHub Actions booleans come as literal 'true'/'false' strings
          ABLATION_LIST=""
          if [[ "${INPUT_RUN_ALL_DEFAULT}" == "true" ]]; then
            ABLATION_LIST="${DEFAULT_ABLATIONS}"
            echo "Using default ablations: ${ABLATION_LIST}"
          elif [[ -n "${INPUT_ABLATIONS}" ]]; then
            ABLATION_LIST="${INPUT_ABLATIONS}"
            echo "Using input ablations: ${ABLATION_LIST}"
          else
            echo "No ablations specified - baseline only"
          fi

          # Export to GITHUB_OUTPUT for subsequent steps
          echo "suite_path=${SUITE_PATH}" >> "$GITHUB_OUTPUT"
          echo "suite_out_dir=${SUITE_OUT_DIR}" >> "$GITHUB_OUTPUT"
          echo "ablation_list=${ABLATION_LIST}" >> "$GITHUB_OUTPUT"
          echo "run_root=${RUN_ROOT}" >> "$GITHUB_OUTPUT"
          echo "report_dir=${REPORT_DIR}" >> "$GITHUB_OUTPUT"

      # =========================================================================
      # Create output directories
      # =========================================================================

      - name: Initialize output directories
        shell: bash
        run: |
          set -euo pipefail

          RUN_ROOT="${{ steps.config.outputs.run_root }}"
          REPORT_DIR="${{ steps.config.outputs.report_dir }}"

          echo "Creating output directories..."
          mkdir -p "${RUN_ROOT}"
          mkdir -p "${REPORT_DIR}"

          echo "RUN_ROOT=${RUN_ROOT}"
          echo "REPORT_DIR=${REPORT_DIR}"

          # Write determinism metadata using Python for proper JSON escaping
          python3 << 'PYEOF'
          import json
          from datetime import datetime, timezone

          metadata = {
              "github_run_id": "${{ github.run_id }}",
              "github_run_attempt": "${{ github.run_attempt }}",
              "github_sha": "${{ github.sha }}",
              "github_ref": "${{ github.ref }}",
              "github_actor": "${{ github.actor }}",
              "suite_path": "${{ steps.config.outputs.suite_path }}",
              "ablation_list": "${{ steps.config.outputs.ablation_list }}",
              "timestamp_utc": datetime.now(timezone.utc).isoformat()
          }

          with open("${{ steps.config.outputs.run_root }}/ci_metadata.json", "w") as f:
              json.dump(metadata, f, indent=2)
          PYEOF

          echo "‚úì Directories initialized"
          echo "‚úì CI metadata written to ${RUN_ROOT}/ci_metadata.json"

      # =========================================================================
      # Run baseline
      # =========================================================================

      - name: Run baseline suite
        shell: bash
        run: |
          set -euo pipefail

          SUITE_PATH="${{ steps.config.outputs.suite_path }}"
          SUITE_OUT_DIR="${{ steps.config.outputs.suite_out_dir }}"
          RUN_ROOT="${{ steps.config.outputs.run_root }}"

          echo "=== Running baseline suite ==="
          echo "Suite: ${SUITE_PATH}"
          echo "Suite out_dir: ${SUITE_OUT_DIR}"
          echo "Run root: ${RUN_ROOT}"

          # Run the suite - sim_eval appends __baseline suffix automatically
          ./target/release/sim_eval suite "${SUITE_PATH}" \
            2>&1 | tee "${RUN_ROOT}/baseline_run.log"

          # Move outputs from suite's out_dir to our unique run root
          SOURCE_DIR="${SUITE_OUT_DIR}__baseline"
          DEST_DIR="${RUN_ROOT}/research__baseline"

          if [[ -d "${SOURCE_DIR}" ]]; then
            echo "Moving ${SOURCE_DIR} -> ${DEST_DIR}"
            mv "${SOURCE_DIR}" "${DEST_DIR}"
          else
            echo "WARNING: Expected baseline output directory not found: ${SOURCE_DIR}"
            echo "Listing parent directory:"
            ls -la "$(dirname "${SOURCE_DIR}")" || true
          fi

          echo ""
          echo "=== Baseline complete ==="
          ls -la "${RUN_ROOT}" || true

      # =========================================================================
      # Run ablation variants
      # =========================================================================

      - name: Run ablation variants
        shell: bash
        run: |
          set -euo pipefail

          SUITE_PATH="${{ steps.config.outputs.suite_path }}"
          SUITE_OUT_DIR="${{ steps.config.outputs.suite_out_dir }}"
          RUN_ROOT="${{ steps.config.outputs.run_root }}"
          ABLATION_LIST="${{ steps.config.outputs.ablation_list }}"

          if [[ -z "${ABLATION_LIST}" ]]; then
            echo "No ablations specified - skipping ablation runs"
            exit 0
          fi

          echo "=== Running ablation variants ==="
          echo "Suite: ${SUITE_PATH}"
          echo "Suite out_dir: ${SUITE_OUT_DIR}"
          echo "Run root: ${RUN_ROOT}"
          echo "Ablation list: ${ABLATION_LIST}"

          # Convert comma-separated list to sorted array (deterministic order)
          IFS=',' read -r -a ABLATIONS_RAW <<< "${ABLATION_LIST}"
          ABLATIONS=()
          for a in "${ABLATIONS_RAW[@]}"; do
            trimmed="$(echo "${a}" | xargs)"
            if [[ -n "${trimmed}" ]]; then
              ABLATIONS+=("${trimmed}")
            fi
          done

          # Sort for deterministic iteration order
          IFS=$'\n' ABLATIONS_SORTED=($(printf '%s\n' "${ABLATIONS[@]}" | sort))
          unset IFS

          echo "Sorted ablations (${#ABLATIONS_SORTED[@]}):"
          printf '  - %s\n' "${ABLATIONS_SORTED[@]}"
          echo ""

          # Run each ablation sequentially
          for ablation in "${ABLATIONS_SORTED[@]}"; do
            echo "‚îÅ‚îÅ‚îÅ Ablation: ${ablation} ‚îÅ‚îÅ‚îÅ"

            ./target/release/sim_eval suite "${SUITE_PATH}" --ablation "${ablation}" \
              2>&1 | tee "${RUN_ROOT}/${ablation}_run.log"

            # Move outputs from suite's out_dir to our unique run root
            SOURCE_DIR="${SUITE_OUT_DIR}__${ablation}"
            DEST_DIR="${RUN_ROOT}/research__${ablation}"

            if [[ -d "${SOURCE_DIR}" ]]; then
              echo "Moving ${SOURCE_DIR} -> ${DEST_DIR}"
              mv "${SOURCE_DIR}" "${DEST_DIR}"
            else
              echo "WARNING: Expected ablation output directory not found: ${SOURCE_DIR}"
              echo "Listing parent directory:"
              ls -la "$(dirname "${SOURCE_DIR}")" || true
            fi

            echo ""
          done

          echo "=== All ablations complete ==="
          ls -la "${RUN_ROOT}"

      # =========================================================================
      # Generate research report
      # =========================================================================

      - name: Generate research report
        id: report
        shell: bash
        run: |
          set -euo pipefail

          RUN_ROOT="${{ steps.config.outputs.run_root }}"
          REPORT_DIR="${{ steps.config.outputs.report_dir }}"

          echo "=== Generating research report ==="
          echo "Run root: ${RUN_ROOT}"
          echo "Report dir: ${REPORT_DIR}"

          # Ensure report directory exists
          mkdir -p "${REPORT_DIR}"

          # Run the quant-grade research report script
          # Exit codes: 0=success, 1=kill-switch triggered, 2=critical error
          # We capture exit code to allow workflow to continue for artifact upload
          REPORT_EXIT=0
          python3 tools/sim_eval_report.py \
              --run-root "${RUN_ROOT}" \
              --out-dir "${REPORT_DIR}" || REPORT_EXIT=$?

          echo "report_exit_code=${REPORT_EXIT}" >> "$GITHUB_OUTPUT"

          echo ""
          echo "=== Report generation complete (exit: ${REPORT_EXIT}) ==="
          ls -la "${REPORT_DIR}"

          # Exit 2 = critical error, fail immediately
          if [[ "${REPORT_EXIT}" -eq 2 ]]; then
            echo "‚ùå Critical error in report generation"
            exit 2
          fi

          # Exit 1 = kill switch triggered, note but continue
          if [[ "${REPORT_EXIT}" -eq 1 ]]; then
            echo "‚ö† Kill switch triggered in one or more runs (reports generated)"
          fi

      # =========================================================================
      # Write GitHub Step Summary
      # =========================================================================

      - name: Write executive summary
        shell: bash
        run: |
          set -euo pipefail

          REPORT_DIR="${{ steps.config.outputs.report_dir }}"
          ABLATION_LIST="${{ steps.config.outputs.ablation_list }}"

          # Write CI context header
          # Note: The report generator (sim_eval_report.py) already wrote the
          # delta overview table to GITHUB_STEP_SUMMARY. We add context here.
          {
            echo "## üî¨ sim_eval Research Run"
            echo ""
            echo "| Field | Value |"
            echo "|-------|-------|"
            echo "| **Run ID** | \`${{ github.run_id }}\` (attempt ${{ github.run_attempt }}) |"
            echo "| **SHA** | \`${{ github.sha }}\` |"
            echo "| **Suite** | \`${{ steps.config.outputs.suite_path }}\` |"
            echo "| **Ablations** | \`${ABLATION_LIST:-baseline only}\` |"
            echo ""
            echo "---"
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"

          # Append the full research report (includes delta tables)
          if [[ -f "${REPORT_DIR}/research_report.md" ]]; then
            cat "${REPORT_DIR}/research_report.md" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "‚ö† No research report generated" >> "$GITHUB_STEP_SUMMARY"
          fi

      # =========================================================================
      # Validation
      # =========================================================================

      - name: Validate outputs
        shell: bash
        run: |
          set -euo pipefail

          RUN_ROOT="${{ steps.config.outputs.run_root }}"
          REPORT_DIR="${{ steps.config.outputs.report_dir }}"

          echo "=== Validating outputs ==="
          ERRORS=0

          # Check 1: At least one run_summary.json exists
          echo "Checking for run_summary.json files..."
          SUMMARY_COUNT=$(find "${RUN_ROOT}" -name "run_summary.json" -type f | wc -l)
          if [[ "${SUMMARY_COUNT}" -lt 1 ]]; then
            echo "‚ùå ERROR: No run_summary.json files found under ${RUN_ROOT}"
            ERRORS=$((ERRORS + 1))
          else
            echo "‚úì Found ${SUMMARY_COUNT} run_summary.json file(s)"
          fi

          # Check 2: Report files exist
          echo "Checking for report files..."
          if [[ ! -f "${REPORT_DIR}/research_report.md" ]]; then
            echo "‚ùå ERROR: Missing ${REPORT_DIR}/research_report.md"
            ERRORS=$((ERRORS + 1))
          else
            echo "‚úì Found ${REPORT_DIR}/research_report.md"
          fi

          if [[ ! -f "${REPORT_DIR}/research_report.json" ]]; then
            echo "‚ùå ERROR: Missing ${REPORT_DIR}/research_report.json"
            ERRORS=$((ERRORS + 1))
          else
            echo "‚úì Found ${REPORT_DIR}/research_report.json"
          fi

          # Check 3: CI metadata exists
          if [[ ! -f "${RUN_ROOT}/ci_metadata.json" ]]; then
            echo "‚ùå ERROR: Missing ${RUN_ROOT}/ci_metadata.json"
            ERRORS=$((ERRORS + 1))
          else
            echo "‚úì Found ${RUN_ROOT}/ci_metadata.json"
          fi

          # Summary
          echo ""
          echo "=== Validation Summary ==="
          echo "Run root contents:"
          find "${RUN_ROOT}" -type f -name "*.json" | head -20 | sort
          echo ""
          echo "Report dir contents:"
          ls -la "${REPORT_DIR}"

          if [[ "${ERRORS}" -gt 0 ]]; then
            echo ""
            echo "‚ùå Validation failed with ${ERRORS} error(s)"
            exit 1
          fi

          echo ""
          echo "‚úì All validations passed"

      # =========================================================================
      # Verify and bundle evidence packs
      # =========================================================================

      - name: Verify and bundle evidence packs
        shell: bash
        run: |
          set -euo pipefail

          echo "=== Finding evidence packs ==="

          # Find all SHA256SUMS files in evidence_pack directories
          SUMS_FILES=$(find . -type f -path '*/evidence_pack/SHA256SUMS' | sort)

          if [[ -z "${SUMS_FILES}" ]]; then
            echo "‚ùå ERROR: No evidence_pack/SHA256SUMS files found"
            exit 1
          fi

          # Count and list evidence packs
          PACK_COUNT=$(echo "${SUMS_FILES}" | wc -l)
          echo "Found ${PACK_COUNT} evidence pack(s):"
          echo "${SUMS_FILES}"
          echo ""

          # Verify each evidence pack
          echo "=== Verifying evidence packs ==="
          OUTPUT_ROOTS=()

          while IFS= read -r sums_file; do
            # Get output_root (2 levels above SHA256SUMS)
            evidence_pack_dir=$(dirname "${sums_file}")
            output_root=$(dirname "${evidence_pack_dir}")
            OUTPUT_ROOTS+=("${output_root}")

            echo "Verifying: ${output_root}"
            (cd "${output_root}" && sha256sum -c evidence_pack/SHA256SUMS)
            echo "‚úì Verified: ${output_root}"
            echo ""
          done <<< "${SUMS_FILES}"

          echo "=== Creating deterministic bundle ==="

          # Build file list from SHA256SUMS entries (paths relative to repo root)
          > evidence_pack_files.txt

          while IFS= read -r sums_file; do
            evidence_pack_dir=$(dirname "${sums_file}")
            output_root=$(dirname "${evidence_pack_dir}")

            # Read each line from SHA256SUMS and convert to repo-relative path
            while IFS= read -r line; do
              # SHA256SUMS format: <hash>  <relative_path>
              # Extract the path (everything after the hash and two spaces)
              file_path="${line#*  }"
              repo_relative="${output_root}/${file_path}"
              # Normalize path (remove leading ./)
              repo_relative="${repo_relative#./}"
              echo "${repo_relative}" >> evidence_pack_files.txt
            done < "${sums_file}"
          done <<< "${SUMS_FILES}"

          # Also include SHA256SUMS files themselves (required for post-download verification)
          echo "${SUMS_FILES}" | sed 's|^\./||' >> evidence_pack_files.txt

          # Deduplicate and sort
          sort -u evidence_pack_files.txt -o evidence_pack_files.txt

          FILE_COUNT=$(wc -l < evidence_pack_files.txt)
          echo "Bundle will contain ${FILE_COUNT} files"

          # Create deterministic tarball
          # Check if GNU tar is available with required flags
          if tar --version 2>/dev/null | grep -q 'GNU tar'; then
            echo "Using GNU tar for deterministic archive"
            tar --sort=name --mtime='UTC 1970-01-01' --owner=0 --group=0 --numeric-owner \
              -cf evidence_pack_bundle.tar -T evidence_pack_files.txt
          else
            echo "WARNING: GNU tar not detected, falling back to basic tar (less deterministic)"
            tar -cf evidence_pack_bundle.tar -T evidence_pack_files.txt
          fi

          gzip -n evidence_pack_bundle.tar

          # Hard assertion: verify all SHA256SUMS files are in the bundle
          expected_count=$(find . -type f -path '*/evidence_pack/SHA256SUMS' | wc -l | tr -d ' ')
          actual_count=$(tar -tzf evidence_pack_bundle.tar.gz | grep -c '/evidence_pack/SHA256SUMS$' || true)
          if [ "$actual_count" -ne "$expected_count" ]; then
            echo "ERROR: bundle missing SHA256SUMS files (expected=$expected_count actual=$actual_count)"
            echo "This breaks post-download verification."
            exit 1
          fi
          echo "‚úì Verified bundle contains all ${expected_count} SHA256SUMS file(s)"

          # ---------------------------------------------------------------
          # Run strict evidence tree verifier (requires debug build)
          # ---------------------------------------------------------------
          echo "=== Building sim_eval (debug) for verification ==="
          cargo build --locked -p paraphina --bin sim_eval
          echo "‚úì sim_eval (debug) built successfully"

          echo "=== Verifying extracted bundle with evidence tree verifier ==="
          mkdir -p verify_extract
          tar -xzf evidence_pack_bundle.tar.gz -C verify_extract
          ./target/debug/sim_eval verify-evidence-tree verify_extract
          echo "‚úì Evidence tree verifier passed"

          # Compute and print sha256 of bundle
          BUNDLE_SHA256=$(sha256sum evidence_pack_bundle.tar.gz | cut -d' ' -f1)
          echo ""
          echo "‚úì Bundle created: evidence_pack_bundle.tar.gz"
          echo "  SHA256: ${BUNDLE_SHA256}"

          # Write step summary
          echo "=== Writing step summary ==="
          {
            echo ""
            echo "---"
            echo ""
            echo "## üì¶ Evidence Pack Bundle"
            echo ""
            echo "| Metric | Value |"
            echo "|--------|-------|"
            echo "| **Evidence packs found** | ${PACK_COUNT} |"
            echo "| **Files in bundle** | ${FILE_COUNT} |"
            echo "| **Bundle SHA256** | \`${BUNDLE_SHA256}\` |"
            echo ""
            echo "### Output directories"
            echo ""
            printf '%s\n' "${OUTPUT_ROOTS[@]}" | sed 's/^/- `/' | sed 's/$/`/'
            echo ""
            echo "### Verification after download"
            echo ""
            echo '```bash'
            echo 'tar -xzf evidence_pack_bundle.tar.gz'
            for root in "${OUTPUT_ROOTS[@]}"; do
              # Normalize the root path
              normalized="${root#./}"
              echo "(cd \"${normalized}\" && sha256sum -c evidence_pack/SHA256SUMS)"
            done
            echo '```'
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"

          echo "‚úì Evidence pack verification and bundling complete"

      - name: Upload evidence pack bundle
        uses: actions/upload-artifact@v4
        with:
          name: evidence-pack-v1
          path: |
            evidence_pack_bundle.tar.gz
            evidence_pack_files.txt
          retention-days: 14
          if-no-files-found: error

      # =========================================================================
      # Upload artifacts
      # =========================================================================

      - name: Upload run summaries
        uses: actions/upload-artifact@v4
        with:
          name: run-summaries-${{ github.run_id }}
          path: |
            ${{ steps.config.outputs.run_root }}/
          retention-days: 14
          if-no-files-found: error

      - name: Upload research reports
        uses: actions/upload-artifact@v4
        with:
          name: research-reports-${{ github.run_id }}
          path: |
            ${{ steps.config.outputs.report_dir }}/research_report.md
            ${{ steps.config.outputs.report_dir }}/research_report.json
          retention-days: 14
          if-no-files-found: error

      # =========================================================================
      # Final status check
      # =========================================================================

      - name: Check for kill switches
        shell: bash
        run: |
          set -euo pipefail

          REPORT_EXIT="${{ steps.report.outputs.report_exit_code }}"

          if [[ "${REPORT_EXIT}" -eq 1 ]]; then
            echo "‚ùå Workflow completed but kill switch(es) were triggered."
            echo "   Review the research report artifacts for details."
            exit 1
          fi

          echo "‚úì Research run completed successfully with no kill switches"
